{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MAD GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Initialization of libraries\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from random import randint\n",
    "from sklearn.mixture import GMM\n",
    "device = torch.device('cuda')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameters for the training\n",
    "mb_size = 128 # Batch Size\n",
    "Z_dim = 64  # Length of noise vector\n",
    "X_dim = 1  # Input Length\n",
    "h_dim = 128  # Hidden Dimension\n",
    "lr = 1e-4    # Learning Rate\n",
    "num_gen = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "gmm = GMM(5)\n",
    "gmm.means_ = np.array([[10], [20], [60], [80], [110]])\n",
    "gmm.covars_ = np.array([[3], [3], [2], [2], [1]]) ** 2\n",
    "gmm.weights_ = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "\n",
    "X = gmm.sample(200000)\n",
    "data = X\n",
    "data = (data - X.min())/(X.max()-X.min())\n",
    "plt.hist(data, 200000, normed=False, histtype='stepfilled', alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "G = []\n",
    "for i in range(num_gen):\n",
    "    G.append(torch.nn.Sequential(\n",
    "        torch.nn.Linear(Z_dim, h_dim),\n",
    "        torch.nn.PReLU(),\n",
    "        torch.nn.Linear(h_dim, h_dim),\n",
    "        torch.nn.PReLU(),\n",
    "        torch.nn.Linear(h_dim, X_dim),\n",
    "        torch.nn.Sigmoid()\n",
    "    ).cuda())\n",
    "\n",
    "D = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_dim, h_dim),\n",
    "    torch.nn.LeakyReLU(0.2),\n",
    "    torch.nn.Linear(h_dim, h_dim),\n",
    "    torch.nn.LeakyReLU(0.2),\n",
    "    torch.nn.Linear(h_dim, num_gen + 1),\n",
    "    torch.nn.Softmax()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "G_solver = []\n",
    "for i in range(num_gen):\n",
    "    G_solver.append(optim.Adam(G[i].parameters(), lr))\n",
    "D_solver = optim.Adam(D.parameters(), lr)\n",
    "###\n",
    "loss = nn.CrossEntropyLoss()\n",
    "label_G = Variable(torch.LongTensor(mb_size))\n",
    "label_G = label_G.to(device)\n",
    "label_D = Variable(torch.LongTensor(mb_size))\n",
    "label_D = label_D.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the gradients to zero\n",
    "params = [G[0], G[1], G[2], G[3], D]\n",
    "def reset_grad():\n",
    "    for net in params:\n",
    "        net.zero_grad()\n",
    "reset_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "for it in range(198000):\n",
    "    if ((data_index + 1)*mb_size>len(data)):\n",
    "        data_index = 0\n",
    "\n",
    "    X.view(mb_size, 1)\n",
    "    X = X.type(torch.FloatTensor)\n",
    "    X = X. X = torch.from_numpy(np.array(data[data_index*mb_size : (data_index + 1)*mb_size]))\n",
    "    X =to(device)\n",
    "    Total_D_loss = 0\n",
    "    for i in range(num_gen):\n",
    "        # Dicriminator forward-loss-backward-update\n",
    "        #forward pass\n",
    "        z = torch.FloatTensor(mb_size, Z_dim).uniform_(-1, 1)\n",
    "        z = z.to(device)\n",
    "        G_sample = G[i](z)\n",
    "        D_real = D(X)\n",
    "        D_fake = D(G_sample)\n",
    "        # Calculate the loss\n",
    "        D_loss_real = loss(D_real,label_D.fill_(num_gen + 0.1*randint(-1,1)))\n",
    "        D_loss_fake = loss(D_fake, label_G.fill_(i + 0.1*randint(-1,1)))\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "        Total_D_loss = D_loss + Total_D_loss\n",
    "        # Calulate and update gradients of discriminator\n",
    "        D_loss.backward()\n",
    "        D_solver.step()\n",
    "\n",
    "        # reset gradient\n",
    "        reset_grad()\n",
    "\n",
    "    # Generator forward-loss-backward-update\n",
    "    \n",
    "    Total_G_loss = 0\n",
    "    for i in range(num_gen):\n",
    "        \n",
    "        z = torch.FloatTensor(mb_size, Z_dim).uniform_(-1, 1)\n",
    "        z = z.to(device)\n",
    "        G_sample = G[i](z)\n",
    "        D_fake = D(G_sample)\n",
    "\n",
    "        G_loss = loss(D_fake, label_D.fill_(num_gen + 0.1*randint(-1,1)))\n",
    "        Total_G_loss = G_loss + Total_G_loss\n",
    "        G_loss.backward()\n",
    "        G_solver[i].step()\n",
    "\n",
    "        # reset gradient\n",
    "        reset_grad()\n",
    "        \n",
    "    data_index = data_index + 1\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, Total_D_loss.data.cpu().numpy(), Total_G_loss.data.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "final = np.zeros(1500*mb_size, dtype = float)\n",
    "for i in range(1500):\n",
    "    z = torch.FloatTensor(64, Z_dim).uniform_(-1, 1)\n",
    "    z = z.to(device)\n",
    "    l = G[randint(0,num_gen-1)](z).cpu().detach().numpy()\n",
    "    final[i*mb_size : ((i+ 1)*mb_size -1)] = l[0]\n",
    "p1 = plt.hist(final, 200, normed=True, histtype='bar', alpha=0.5)\n",
    "p2 = plt.hist(data, 200, normed=True, histtype='bar', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
